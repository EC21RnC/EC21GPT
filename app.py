# ------------------------------------------------------------------- #
import streamlit as st
import openai
import os
import tiktoken
from gensim.summarization import summarize
from googletrans import Translator
import time
from nltk.tokenize import sent_tokenize
import nltk
nltk.download('punkt')

# https://docs.streamlit.io/library/api-reference
# https://streamlit-emoji-shortcodes-streamlit-app-gwckff.streamlit.app/
# streamlit run app.py
# openai.api_key = st.secrets["api_key"]
# os.environ["api_key"] == st.secrets["api_key"]
openai.organization = "org-cWYPb9h1vIjpstBy0y6td4Sj"
openai.api_key = os.getenv('api_key')
secret_key = os.getenv('secret_key')
# os.environ[]
# ------------------------------------------------------------------- # 
# defs 
# ------------------------------------------------------------------- #
    # count words
def num_tokens_from_string(string: str) -> int:
    """Returns the number of tokens in a text string."""
    encoding = tiktoken.encoding_for_model('curie')
    num_tokens = len(encoding.encode(string))
    return num_tokens

    # summarize
def textRank_summarize(text, ratio):
    # Summarize the text with TextRank
    summary = summarize(text, ratio=ratio)
    return summary

    # generate answer
def generate_answer(input_text, ft_model, temperature):
    # Code to access the GPT-3 API and generate a summary
    completions = openai.Completion.create(
        model = ft_model,
        prompt = input_text + '\n\n###\n\n',
        max_tokens = 500,
        stop = ' END',
        temperature = temperature,
        n = 1
    )
    message = completions.choices[0].text
    return message

def translate_text(text, source_language, target_language):
    translator = Translator()
    result = translator.translate(text, src=source_language, dest=target_language)
    # print("Translation result:", result)
    return result.text


def translate_long_text(text):
    sentences = sent_tokenize(text)

    translated_text = ""
    current_chunk = []
    current_chunk_length = 0

    for sentence in sentences:
        sentence_length = len(sentence)

        if current_chunk_length + sentence_length > 3000:
            try:
                try:
                    translated_sentences = translate_text(" ".join(current_chunk), "en", "ko")
                except:
                    time.sleep(2)
                    translated_sentences = translate_text(" ".join(current_chunk), "en", "ko")
            except:
                translated_sentences = ''
            translated_text += "".join(translated_sentences)
            current_chunk = [sentence]
            current_chunk_length = sentence_length
        else:
            current_chunk.append(sentence)
            current_chunk_length += sentence_length

    if current_chunk:
        # print("Translating chunk:", " ".join(current_chunk))
        try:
            try:
                translated_sentences = translate_text(" ".join(current_chunk), "en", "ko")
            except:
                time.sleep(2)
                translated_sentences = translate_text(" ".join(current_chunk), "en", "ko")
        except:
            translated_sentences = ''
        translated_text += "".join(translated_sentences)
        
    return translated_text
# ------------------------------------------------------------------- #
# ------------------------------------------------------------------- #

# Initialize the history in the session state
if "history" not in st.session_state:
    st.session_state["history"] = []
# Create the history tab in the sidebar
st.sidebar.markdown('# 	:speech_balloon: History')
st.sidebar.caption(':warning: í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ë©´ íˆìŠ¤í† ë¦¬ê°€ ì‚¬ë¼ì§‘ë‹ˆë‹¤')
st.sidebar.markdown('---')

models = {
    'íŒŒì¸íŠœë‹_curie_513' : 'curie:ft-ec21rnc-2023-05-31-09-57-57',
    'íŒŒì¸íŠœë‹_curie_1837' : 'curie:ft-ec21rnc-2023-06-07-06-37-34',
    'ê¸°ë³¸ëª¨ë¸_GPT-4' : 'gpt-4'
}
guide = """Forget all the previous Intructions. As a professional journalist with exceptional English writing skills, your task is to provide a comprehensive summary of the given news articles. To accomplish this, you must first create a suitable title in a full sentence. Next, you must identify at least three main points from the articles. Your summary should cover all three of these main points, with each point accompanied by three explanatory sentences. It is essential that you present the main points and their corresponding explanations in a logical and chronological sequence, with a clear connection to the topic. Your summary must cover all aspects of the provided articles, and you should not include any information outside of the passage. Additionally, avoid repeating facts or writing similar sentences. Finally, your response should consist solely of the summary, without any supplementary commentary. When referring to numerical data, such as market size, growth, budget, or rate, be sure to use the provided index.
Now, create a summary based on the provided articles below:"""
# ------------------------------------------------------------------- #
# ------------------------------------------------------------------- #
#
#



#
#

    # Title
st.title(":blue[EC21R&C] SummaryGPT")
st.divider()
instructions = '''> 1. ê¸°ì‚¬ì…ë ¥ì°½ì— ìš”ì•½ ëŒ€ìƒ ê¸°ì‚¬ë¥¼ í˜•ì‹ëŒ€ë¡œ ë¶™í˜€ ë„£ê³ , `í† í° ìˆ˜ ê³„ì‚°` ë²„íŠ¼ì„ ëˆ„ë¥¸ë‹¤.
> 2. 1500ì ì´ìƒì¼ ê²½ìš°, ë³´ë‹¤ ì •í™•í•œ ê²°ê³¼ë¥¼ ìœ„í•´ ì£¼ì œì™€ í•„ìš”ì—†ëŠ” ë¬¸ì¥, ë¬¸ë‹¨ ë“±ì„ ì§€ìš°ê³  ë‹¤ì‹œ í† í°ìˆ˜ë¥¼ ê³„ì‚°í•œë‹¤.
> 3. ë¬¸ë‹¨ì„ ì§€ìš¸ í•„ìš”ê°€ ì—†ë‹¤ë©´, `Secret Key`, `GPT Model`, `Temperature`ë¥¼ ì„ íƒí•˜ê³  `ìš”ì•½ë¬¸ ìƒì„±`ì„ í´ë¦­í•œë‹¤.'''
st.subheader(':bulb: ì‚¬ìš©ë²•')
st.markdown(instructions)
# st.info(instructions)
st.divider()
    # pre-set
# st.header('í† í° ìˆ˜ ê³„ì‚°')
# ------------------------------------------------------------------- #
# ------------------------------------------------------------------- #
placeholder = """[ê¸°ì‚¬1 ì œëª©]
[ê¸°ì‚¬1 ë‚´ìš©]
[ê¸°ì‚¬2 ì œëª©]
[ê¸°ì‚¬2 ë‚´ìš©]
...
"""

with st.form("form_count_tokens"):
    user_input = st.text_area("**Prompt (ê¸°ì‚¬ì…ë ¥ì°½)**", placeholder = placeholder, height = 500)
    user_input = user_input.replace('\n\n', ' ').replace('\n', ' ').strip()
    submit = st.form_submit_button(":moneybag: **í† í° ìˆ˜ ê³„ì‚°** :moneybag:", use_container_width = True)
    

if submit and user_input:
    with st.spinner("calculating tokens..."):
        token_num = num_tokens_from_string(user_input)
    st.subheader( 'í† í°ìˆ˜ : ' + str(token_num) + ' tokens' )
    st.caption('_1500 í† í°ì„ ë„˜ì–´ê°€ë©´ ê¸°ì‚¬ê°€ ìë™ìœ¼ë¡œ ìš”ì•½ë˜ì–´ì„œ GPTì— ì…ë ¥ë©ë‹ˆë‹¤_')
else:
    if submit and len(user_input) == 0:
        st.error('í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”', icon="ğŸš¨")

# ------------------------------------------------------------------- #
# ------------------------------------------------------------------- #



    
# ------------------------------------------------------------------- #
# ------------------------------------------------------------------- #
with st.form("form_gpt"):
        # secret key
    secret_key_user = st.text_input(':secret: **Secret Key**', placeholder = 'chan@ec21rnc.comì— ë¬¸ì˜í•´ì£¼ì„¸ìš”')
        # model selection
    model = st.selectbox("**GPT Model ì„ íƒ**", ["íŒŒì¸íŠœë‹_curie_1837", "íŒŒì¸íŠœë‹_curie_513"])
        # temperature
    temperature = st.selectbox("**Temperature**", ["0.5", "0", "0.3", "0.7", "1"])
    st.caption('â†’ _ë‚®ì„ìˆ˜ë¡ ì •í˜•í™”ëœ ë‹µë³€ ìƒì„±, ë†’ì„ìˆ˜ë¡ ììœ ë¡­ê²Œ ë¬¸ì¥ì„ ìƒì„±_')
        # translate_y_n
    translate_y_n = st.selectbox("**ë‹µë³€ì„ í•œê¸€ë¡œ ë²ˆì—­**", ["No", "Yes"])
    st.caption('â†’ _êµ¬ê¸€ ë²ˆì—­ê¸° ì‚¬ìš© ì¤‘. ì¶”í›„ íŒŒì¸íŠœë‹ ëª¨ë¸ë¡œ ë³€ê²½ ì˜ˆì •_')
        # submit
    submit_summary = st.form_submit_button(":printer: **ìš”ì•½ë¬¸ ìƒì„±** :printer:", use_container_width = True)
    
    # with st.form("form"):
st.divider()

if submit_summary and secret_key == secret_key_user and user_input:
    user_input = user_input.replace('\n\n', ' ').replace('\n', ' ').strip()
    if num_tokens_from_string(user_input) > 1200:
        with st.spinner("Summarizing Text..."):
            target_token_num = 1200
            ratio = target_token_num / num_tokens_from_string(user_input)
            ratio = round(ratio, ndigits=1)

            while True:
                # Summarize the text
                summary = textRank_summarize(user_input, ratio)
                summary_tokens = num_tokens_from_string(summary)

                # If the summary is short enough, stop here
                if summary_tokens <= target_token_num:
                    break

                # Otherwise, reduce the ratio and try again
                ratio -= 0.1

            user_input = summary
    with st.spinner("Waiting for ChatGPT..."):
        # user_input = user_input
        # user_input = guide + '\n' + user_input
        prompt = generate_answer(user_input, models.get(model), float(temperature))
    # with st.container():
    if translate_y_n == 'No':
            # write text
        st.markdown(prompt.replace('>>', '\nâ˜').replace('.-', '\n&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;'))
        st.code(prompt, language = 'markdown')
        # add to history
        st.session_state["history"].append(prompt + '\n' + 'Temperature: ' +  str(temperature) + '\n' + 'Model: ' + str(model))
    elif translate_y_n == 'Yes':
        st.subheader('ì˜ë¬¸')
            # en result
        st.markdown(prompt.replace('>>', '\nâ˜').replace('.-', '\n&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;'))
        st.code(prompt, language = 'markdown')
        st.divider()
            # ko result
        st.subheader('í•œê¸€')
        ts_text = translate_long_text(prompt)
        ts_text = ts_text.replace('.-', '.\n - ').replace('>>', '\n>>')
        st.markdown(ts_text.replace('>>', '\nâ˜').replace('.-', '\n&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;'))
        st.code(ts_text, language = 'markdown')
        st.divider()
        # add to history
        st.session_state["history"].append(prompt + '\n' + 'Temperature: ' +  str(temperature) + '\n' + 'Model: ' + str(model))
    # st.sidebar
    # st.sidebar.text_area("History", st.session_state["history"], height=200)

    # st.write(prompt.replace('Title:', '').replace('(*)', '').replace('>>', '').replace('-', '') )
    # st.write(prompt.replace('Title:', '')) #.replace('(*)', '##').replace('>>', '###') )
    # st.write(prompt.replace('Title:', '').replace('(*)', '##').replace('>>', '###') )
    # st.text(prompt.replace('Title:', '').replace('(*)', '##').replace('>>', '###') )

elif len(user_input) == 0 and submit_summary:
    st.error('í† í° ìˆ˜ ê³„ì‚°ì„ ë¨¼ì € í´ë¦­í•˜ì„¸ìš”', icon="ğŸš¨")
elif len(user_input) != 0 and submit_summary and len(secret_key_user) != 0 and secret_key != secret_key_user:
    st.error('ì˜¬ë°”ë¥¸ `Secret Key`ë¥¼ ì…ë ¥í•˜ì„¸ìš”', icon="ğŸš¨")
elif len(user_input) != 0 and submit_summary and len(secret_key_user) == 0:
    st.error('`Secret Key`ë¥¼ ì…ë ¥í•˜ì„¸ìš”', icon="ğŸš¨")
else:
    pass

# add to history
for i, item in enumerate(st.session_state["history"]):
    with st.sidebar.expander(f"Your Summary #{i+1}"):
        st.code(item, language = 'markdown')